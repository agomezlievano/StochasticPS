{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\python36.zip',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\agomez\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\agomez\\\\.ipython',\n",
       " 'C:\\\\Users\\\\agomez\\\\Dropbox\\\\Harvard\\\\LittleProjects\\\\StochasticPS\\\\programs\\\\']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Allow imports from parent directory \n",
    "# https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im/35273613#35273613\n",
    "#module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "module_path = 'C:\\\\Users\\\\agomez\\\\Dropbox\\\\Harvard\\\\LittleProjects\\\\StochasticPS\\\\programs\\\\'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "def ends(df, x=5):\n",
    "    return df.head(x).append(df.tail(x))\n",
    "setattr(pd.DataFrame,'ends',ends)\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "import warnings\n",
    "import IPython.display\n",
    "import scipy.stats\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rc('font', family='serif', serif='Helvetica')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=16, linewidth=0.5)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "\n",
    "from numpy.random import exponential, negative_binomial, randint, choice, binomial\n",
    "from random import shuffle\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "LETTERS = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "import time\n",
    "from scipy import interpolate\n",
    "\n",
    "import EComm_0001_complexities \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths\n",
    "path_fig = 'C:\\\\Users\\\\agomez\\\\Dropbox\\\\Harvard\\\\LittleProjects\\\\StochasticPS\\\\figures\\\\'\n",
    "path_data = 'C:\\\\Users\\\\agomez\\\\Dropbox\\\\Harvard\\\\LittleProjects\\\\StochasticPS\\\\data\\\\'\n",
    "path_outputdata = 'C:\\\\Users\\\\agomez\\\\Dropbox\\\\Harvard\\\\LittleProjects\\\\StochasticPS\\\\outputdata\\\\'\n",
    "path_inputdata = 'C:\\\\Users\\\\agomez\\\\Dropbox\\\\Harvard\\\\LittleProjects\\\\StochasticPS\\\\inputdata\\\\'\n",
    "\n",
    "# format of figures\n",
    "figformat = \"pdf\"\n",
    "save2file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "``https://intl-atlas-downloads.s3.amazonaws.com`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-25f420e0c260>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://intl-atlas-downloads.s3.amazonaws.com/data.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'can not be written'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36mopen_file\u001b[1;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;31m# Finally, create the File instance, and return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m         \u001b[1;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[1;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtables\\hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tables\\utils.py\u001b[0m in \u001b[0;36mcheck_file_access\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcheck_file_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mcheck_file_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mcheck_file_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tables\\utils.py\u001b[0m in \u001b[0;36mcheck_file_access\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[0mparentname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF_OK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"``%s`` does not exist\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"``%s`` is not a directory\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: ``https://intl-atlas-downloads.s3.amazonaws.com`` does not exist"
     ]
    }
   ],
   "source": [
    "hdf = pd.HDFStore(\"https://intl-atlas-downloads.s3.amazonaws.com/data.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classtype = \"sitc\"\n",
    "\n",
    "timestring = \"year\"\n",
    "rowvarstring = 'location_code'\n",
    "rowvarstring_name = 'location_name_short_en'\n",
    "colvarstring = '{classification}_product_code'.format(classification=classtype)\n",
    "valtotalstring = 'export_value'\n",
    "valvarstring = 'export_rca'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpy_filepath = \"https://intl-atlas-downloads.s3.amazonaws.com/country_hsproduct4digit_year.csv.zip\"\n",
    "classtype = \"sitc\"\n",
    "cpy_filepath = \"https://intl-atlas-downloads.s3.amazonaws.com/country_{classification}product4digit_year.csv.zip\".format(classification=classtype)\n",
    "ctyregions_filepath = \"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\"\n",
    "\n",
    "###### LOADING THE DATA #######\n",
    "ctyregs_df = pd.read_csv(ctyregions_filepath)\n",
    "ctyregs_df = ctyregs_df[~ctyregs_df['sub-region'].isnull()]\n",
    "print(ctyregs_df.shape)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cty2reg = ctyregs_df[['region', 'sub-region']]\n",
    "dict_cty2reg.index = ctyregs_df['alpha-3']\n",
    "dict_cty2reg.loc[['AUT', 'USA', 'COL']].region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf = longdf.loc[(~(longdf[\"pci\"].isna()))]\n",
    "longdf[colvarstring] = longdf[colvarstring].apply(lambda x: str(x).zfill(4))\n",
    "#longdf[valtotalstring] = longdf[colvarstring].apply(lambda x: str(x).zfill(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf = longdf[[timestring, rowvarstring_name, rowvarstring, colvarstring, valtotalstring, valvarstring]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding regional data\n",
    "longdf = pd.merge(longdf, \n",
    "                 ctyregs_df[['alpha-3', 'region', 'sub-region']],\n",
    "                 left_on = rowvarstring,\n",
    "                 right_on = 'alpha-3',\n",
    "                 how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(longdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the codes and checking consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_codes = np.sort(longdf[rowvarstring].unique())\n",
    "prod_codes = np.sort(longdf[colvarstring].unique())\n",
    "iso_codes = np.sort(ctyregs_df['alpha-3'].unique())\n",
    "\n",
    "cty_codes = np.array(list(set(exp_codes) & set(iso_codes)))\n",
    "print(len(cty_codes))\n",
    "\n",
    "longdf = longdf.loc[longdf[rowvarstring].isin(cty_codes)]\n",
    "print(longdf.shape)\n",
    "orig_numrows = longdf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping countries and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colvals = longdf.groupby(by = [\"year\", colvarstring])[valtotalstring].sum().reset_index()\n",
    "colvals = colvals.drop(columns = [\"year\"])\n",
    "print(min(colvals.iloc[:,1]))\n",
    "colquants = colvals.quantile([0.01, .25, .5, .75, 0.99])\n",
    "print(colquants)\n",
    "colq = colquants.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products2drop = np.unique(colvals.query(\"export_value < @colq\")[colvarstring])\n",
    "products2drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowvals = longdf.groupby(by = [\"year\", rowvarstring])[valtotalstring].sum().reset_index()\n",
    "rowvals = rowvals.drop(columns = [\"year\"])\n",
    "rowquants = rowvals.quantile([0.01, .25, .5, .75])\n",
    "print(rowquants)\n",
    "rowq = rowquants.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries2drop = np.unique(rowvals.query(\"export_value < @colq\")[rowvarstring])\n",
    "countries2drop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new long matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf_new = longdf.loc[(~(longdf[rowvarstring].isin(countries2drop) | longdf[colvarstring].isin(products2drop)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(longdf_new.shape)\n",
    "longdf_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping only those countries and products present in all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products that are in all years\n",
    "pcodes2keep = longdf_new.loc[((longdf_new['year']==2015) & (longdf_new[valtotalstring]>0.0))][colvarstring].unique()\n",
    "\n",
    "# countries that are in all years\n",
    "ccodes2keep = longdf_new.loc[((longdf_new['year']==2015) & (longdf_new[valtotalstring]>0.0))][rowvarstring].unique()\n",
    "\n",
    "for yr in longdf_new.year.unique():\n",
    "    pcodesyr = longdf_new.loc[((longdf_new['year']==yr) & (longdf_new[valtotalstring]>0.0))][colvarstring].unique()\n",
    "    pcodes2keep = np.array(list(set(pcodes2keep) & set(pcodesyr)))\n",
    "    \n",
    "    ccodesyr = longdf_new.loc[((longdf_new['year']==yr) & (longdf_new[valtotalstring]>0.0))][rowvarstring].unique()\n",
    "    ccodes2keep = np.array(list(set(ccodes2keep) & set(ccodesyr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf_new = longdf_new[longdf_new[rowvarstring].isin(ccodes2keep) & \n",
    "                      longdf_new[colvarstring].isin(pcodes2keep)]\n",
    "print((len(longdf_new.year.unique()), len(longdf_new[rowvarstring].unique()), len(longdf_new[colvarstring].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating totals\n",
    "rowtotalvar = valtotalstring + \"_{}_tot\".format(rowvarstring)\n",
    "coltotalvar = valtotalstring + \"_{}_tot\".format(colvarstring)\n",
    "totaltotalvar = valtotalstring + \"_year_tot\"\n",
    "\n",
    "# ---------------------\n",
    "longdf_new[rowtotalvar] = longdf_new.groupby(by = [\"year\", rowvarstring])[valtotalstring].transform('sum')\n",
    "longdf_new[coltotalvar] = longdf_new.groupby(by = [\"year\", colvarstring])[valtotalstring].transform('sum')\n",
    "longdf_new[totaltotalvar] = longdf_new.groupby(by = [\"year\"])[valtotalstring].transform('sum')\n",
    "\n",
    "longdf_new = longdf_new.loc[(~( (longdf_new[rowtotalvar]<=1000.0) | (longdf_new[coltotalvar]<=1000.0) ))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf_new = longdf_new.drop(columns=[rowtotalvar, coltotalvar, totaltotalvar])\n",
    "# ---------------------\n",
    "longdf_new.loc[:,rowtotalvar] = pd.Series(longdf_new.groupby(by = [\"year\", rowvarstring])[valtotalstring].transform('sum'))\n",
    "longdf_new.loc[:,coltotalvar] = pd.Series(longdf_new.groupby(by = [\"year\", colvarstring])[valtotalstring].transform('sum'))\n",
    "longdf_new.loc[:,totaltotalvar] = pd.Series(longdf_new.groupby(by = [\"year\"])[valtotalstring].transform('sum'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_numrows = longdf_new.shape[0]\n",
    "\n",
    "print(\"The number of rows erased was {}.\".format(orig_numrows - final_numrows))\n",
    "longdf_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(longdf_new[\"year\"].unique()), len(longdf_new[rowvarstring].unique()), len(longdf_new[colvarstring].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf_new.groupby('year', as_index=False).agg({rowvarstring: 'nunique', colvarstring: 'nunique'}).ends(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivon and un-pivot\n",
    "newdf = longdf_new.pivot_table(index=[\"year\", rowvarstring],\n",
    "                            columns=colvarstring,\n",
    "                            values=valtotalstring).fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf_new = pd.merge(newdf.reset_index(level=(\"year\", rowvarstring)).melt(id_vars=[\"year\", rowvarstring], \n",
    "            value_vars=newdf.columns.tolist(),\n",
    "            value_name=valtotalstring)[[\"year\", rowvarstring,colvarstring]],\n",
    "                   longdf_new,\n",
    "                 how = 'left')\n",
    "longdf_new.ends(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating totals\n",
    "rowtotalvar = valtotalstring + \"_{}_tot\".format(rowvarstring)\n",
    "coltotalvar = valtotalstring + \"_{}_tot\".format(colvarstring)\n",
    "totaltotalvar = valtotalstring + \"_year_tot\"\n",
    "\n",
    "# ---------------------\n",
    "longdf_new[rowtotalvar] = longdf_new.groupby(by = [\"year\", rowvarstring])[valtotalstring].transform('sum')\n",
    "longdf_new[coltotalvar] = longdf_new.groupby(by = [\"year\", colvarstring])[valtotalstring].transform('sum')\n",
    "longdf_new[totaltotalvar] = longdf_new.groupby(by = [\"year\"])[valtotalstring].transform('sum')\n",
    "\n",
    "longdf_new = longdf_new.loc[(~( (longdf_new[rowtotalvar]<=1000.0) | (longdf_new[coltotalvar]<=1000.0) ))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating logarithms\n",
    "longdf_new[\"constant\"] = 1\n",
    "longdf_new[\"log_\" + valtotalstring] = np.log(1 + longdf_new[valtotalstring].values)\n",
    "longdf_new[[\"log_\" + rowtotalvar, \"log_\" + coltotalvar, \"log_\" + totaltotalvar]] = np.log(longdf_new[[rowtotalvar, coltotalvar, totaltotalvar]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmat = longdf_new[[\"log_\" + rowtotalvar, \"log_\" + coltotalvar, \"log_\" + totaltotalvar]].values\n",
    "ymat = longdf_new[\"log_\" + valtotalstring].values\n",
    "reg = LinearRegression().fit(Xmat, ymat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the residuals of a regression\n",
    "rcaval = \"rca_ols\"\n",
    "mcpval = \"mcp_ols\"\n",
    "mcporigval = \"mcp_orig\"\n",
    "longdf_new[rcaval] = ymat - reg.predict(Xmat)  \n",
    "longdf_new[mcpval] = (longdf_new[rcaval] > 0).astype(int)  \n",
    "longdf_new[mcporigval] = (longdf_new[valvarstring] > 1).astype(int)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf_new.loc[(longdf_new[\"year\"]==2010)].loc[longdf_new[valvarstring]>0][[valvarstring,rcaval]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(longdf_new.loc[(longdf_new[\"year\"]==2010)].loc[longdf_new[valvarstring]>0][rcaval].values, kde=True, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = longdf_new.loc[(longdf_new[\"year\"]==2010)][rcaval].values\n",
    "y = longdf_new.loc[(longdf_new[\"year\"]==2010)][valvarstring].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(x, y, marker = '.', linestyle=\"\", markersize=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longdf_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide matrix version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widedf_rca = longdf_new.pivot_table(index=[\"year\", rowvarstring],\n",
    "                            columns=colvarstring,\n",
    "                            values=mcpval).fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = 2015\n",
    "# subsetting to year\n",
    "widemat_yr = widedf_rca.query(\"year == @yr\")\n",
    "rsum = widemat_yr.sum(axis=1)\n",
    "csum = widemat_yr.sum(axis=0)\n",
    "irsum = np.argsort(-rsum)\n",
    "icsum = np.argsort(-csum)\n",
    "ctrylist_inorder = np.array(list(zip(*widemat_yr.index.values))[1])[irsum]\n",
    "prodlist_inorder = widemat_yr.columns.values[icsum]\n",
    "\n",
    "# reordering\n",
    "widemat_yr = widemat_yr.reset_index(level=[\"year\"], drop=True).loc[ctrylist_inorder, prodlist_inorder]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Mc2c, Dc, leftVc, rightVc), (Mp2p, Dp, leftVp, rightVp) = EComm_0001_complexities.ECeigenvecs(widemat_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "# histogram of country eigenvalues\n",
    "sns.distplot(Dc.real, bins=50, rug=True, kde=False, norm_hist=True, ax=ax1, axlabel=\"Eigenvalues\")\n",
    "sns.kdeplot(Dc.real, bw=.005, ax=ax1)\n",
    "ax1.set_ylabel(\"Statistical Frequency\")\n",
    "\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "# histogram of country ECI's\n",
    "sns.distplot(leftVc[:,1].real, bins=40, rug=True, kde=False, norm_hist=True, ax=ax2, axlabel=\"2nd left-eigenvector (aka, ECI)\")\n",
    "sns.kdeplot(leftVc[:,1].real, bw=.01, ax=ax2)\n",
    "\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "# histogram of country eigenvalues\n",
    "sns.distplot(Dp.real, bins=50, rug=True, kde=False, norm_hist=True, ax=ax3, axlabel=\"Eigenvalues\")\n",
    "sns.kdeplot(Dp.real, bw=.005, ax=ax3)\n",
    "ax3.set_ylabel(\"Statistical Frequency\")\n",
    "\n",
    "ax4 = fig.add_subplot(2,2,4)\n",
    "# histogram of country ECI's\n",
    "sns.distplot(leftVp[:,1].real, bins=40, rug=True, kde=False, norm_hist=True, ax=ax4, axlabel=\"2nd left-eigenvector (aka, PCI)\")\n",
    "sns.kdeplot(leftVp[:,1].real, bw=.01, ax=ax4)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotUMAP(widedf_rca, yr, ctrylist_inorder, prodlist_inorder, umap_reducer, dict_cty2reg,\n",
    "             change=False, pathname_fig=\"myfig.png\", save=False, **kwargs):\n",
    "\n",
    "    #yr = 2015\n",
    "\n",
    "    # subsetting to year\n",
    "    widemat_yr = widedf_rca.query(\"year == @yr\")\n",
    "\n",
    "    # reordering\n",
    "    widemat_yr = widemat_yr.reset_index(level=[\"year\"], drop=True).loc[ctrylist_inorder, prodlist_inorder]\n",
    "\n",
    "    # applying umap\n",
    "    embedding_yr = umap_reducer.transform(widemat_yr)\n",
    "\n",
    "    plttitle = \"Matrix of presences at time {t}\".format(t=yr)\n",
    "    if change==True:\n",
    "        # subsetting to previous year\n",
    "        widemat_prevyr = widedf_rca.query(\"year == @yr - 1\")\n",
    "        widemat_prevyr = widemat_prevyr.reset_index(level=[\"year\"], drop=True).loc[ctrylist_inorder, prodlist_inorder]\n",
    "        # The change in the matrix\n",
    "        widemat_yr = widemat_yr - widemat_prevyr\n",
    "        plttitle = \"Matrix change from year {tprev} to {t}\".format(tprev = yr-1, t=yr)\n",
    "\n",
    "    # Creating plot\n",
    "    fig = plt.figure(figsize=(24,7))\n",
    "\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    im = ax1.imshow(-widemat_yr, aspect=4, cmap = 'bwr')\n",
    "    ax1.set_title(plttitle, fontsize=25)\n",
    "    fig.colorbar(im, ax=ax1, ticks=np.linspace(-1,1,1))\n",
    "    #ax1 = plt.tight_layout()\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.scatter(embedding_yr[:, 0], embedding_yr[:, 1], \n",
    "                marker = \".\",\n",
    "                **kwargs)\n",
    "    for i, row in enumerate(embedding_yr):\n",
    "        plt.text(row[0], row[1], ctrylist_inorder[i], fontsize = 10, bbox={'facecolor': \"black\", 'alpha':0.3, 'pad':3})\n",
    "    plt.gca().set_aspect('equal', 'datalim')\n",
    "    plt.title('UMAP projection', fontsize=24)\n",
    "\n",
    "    if save:\n",
    "        fig.savefig(pathname_fig)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting initial year\n",
    "yr = 2015\n",
    "\n",
    "# subsetting to year\n",
    "widemat_yr = widedf_rca.query(\"year == @yr\")\n",
    "rsum = widemat_yr.sum(axis=1)\n",
    "csum = widemat_yr.sum(axis=0)\n",
    "irsum = np.argsort(-rsum)\n",
    "icsum = np.argsort(-csum)\n",
    "ctrylist_inorder = np.array(list(zip(*widemat_yr.index.values))[1])[irsum]\n",
    "prodlist_inorder = widemat_yr.columns.values[icsum]\n",
    "\n",
    "# reordering\n",
    "widemat_yr = widemat_yr.reset_index(level=[\"year\"], drop=True).loc[ctrylist_inorder, prodlist_inorder]\n",
    "\n",
    "# fitting umap\n",
    "#umap_reducer = umap.UMAP(random_state=42,\n",
    "#                         metric='jaccard',\n",
    "#                         n_neighbors = 30,\n",
    "#                         min_dist = 0.25).fit(widemat_yr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmapvir = plt.get_cmap('viridis')\n",
    "colors = cmapvir(np.linspace(0,1,len(dict_cty2reg.loc[ctrylist_inorder].region)))\n",
    "clr = [colors[i] for i in range(len(dict_cty2reg.loc[ctrylist_inorder].region))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting umap\n",
    "yr = 2015\n",
    "umap_reducer = umap.UMAP(random_state=42, n_epochs=1000,\n",
    "                         metric='jaccard',\n",
    "                         n_neighbors = 10,\n",
    "                         min_dist = 1).fit(widemat_yr)\n",
    "plotUMAP(widedf_rca, yr, ctrylist_inorder, prodlist_inorder, umap_reducer, dict_cty2reg,\n",
    "         change=True, c = clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = 2015\n",
    "plotUMAP(widedf_rca, yr, ctrylist_inorder, prodlist_inorder, umap_reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allyears = np.sort(longdf_new.year.unique())\n",
    "if False:\n",
    "    for yr in allyears:\n",
    "        plotUMAP(widedf_rca, yr, ctrylist_inorder, prodlist_inorder, umap_reducer, \n",
    "             pathname_fig = path_fig + \"test{t}\".format(t=yr) + \".png\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "allyears = np.sort(longdf_new.year.unique())\n",
    "filenames = [path_fig + \"test{t}\".format(t=yr) + \".png\" for yr in allyears]\n",
    "\n",
    "with imageio.get_writer(path_fig + \"DM_0002_movie.gif\", mode='I') as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import tempfile\n",
    "test_data_home = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context=\"paper\", style=\"white\")\n",
    "\n",
    "\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding = reducer.fit_transform(mnist.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.scatter(\n",
    "    embedding[:, 0], embedding[:, 1], \n",
    "    c=mnist.target, \n",
    "    cmap=\"Spectral\", \n",
    "    #s=0.1, \n",
    "    marker='o',\n",
    ")\n",
    "#plt.setp(ax, xticks=[], yticks=[])\n",
    "plt.title(\"MNIST data embedded into two dimensions by UMAP\", fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(dict_cty2reg.loc[ctrylist_inorder].region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
